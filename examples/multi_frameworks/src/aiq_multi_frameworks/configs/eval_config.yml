# SPDX-FileCopyrightText: Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


general:
  use_uvloop: true
  telemetry:
    logging:
      console:
        _type: console
        level: WARN
      file:
        _type: file
        path: /tmp/multi_frameworks.log
        level: DEBUG
    tracing:
      phoenix:
        _type: phoenix
        endpoint: http://localhost:6006/v1/traces
        project: multi_frameworks

functions:
  internet_search:
    _type: tavily_internet_search
  llama_index_rag:
    _type: llama_index_rag
    llm_name: nim_llm
    model_name : meta/llama-3.1-405b-instruct
    embedding_name : nim_embedder
    data_dir : ./examples/multi_frameworks/README.md
  langchain_researcher_tool:
    _type: langchain_researcher_tool
    web_tool: internet_search
    llm_name: nim_llm
  haystack_chitchat_agent:
    _type: haystack_chitchat_agent
    llm_name: meta/llama-3.1-405b-instruct

llms:
  nim_llm:
    _type: nim
    model_name : meta/llama-3.1-405b-instruct
    temperature: 0.0
  nim_rag_eval_llm:
    _type: nim
    model_name: meta/llama-3.3-70b-instruct
    temperature: 0.0000001
    top_p: 0.0001
    max_tokens: 2
  nim_trajectory_eval_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    max_tokens: 1024

embedders:
  nim_embedder:
    _type: nim
    model_name: nvidia/nv-embedqa-e5-v5
    truncate: END

workflow:
  _type: multi_frameworks
  llm : nim_llm
  data_dir : ./examples/multi_frameworks/README.md
  rag_tool: llama_index_rag
  research_tool: langchain_researcher_tool
  chitchat_agent: haystack_chitchat_agent

eval:
  general:
    output_dir: ./.tmp/aiq/examples/multi_frameworks/
    dataset:
      _type: json
      file_path: examples/multi_frameworks/src/aiq_multi_frameworks/data/eval_data.json
    profiler:
      # Compute inter query token uniqueness
      token_uniqueness_forecast: true
      # Compute expected workflow runtime
      workflow_runtime_forecast: true
      # Compute inference optimization metrics
      compute_llm_metrics: true
      # Avoid dumping large text into the output CSV (helpful to not break structure)
      csv_exclude_io_text: true
      # Idenitfy common prompt prefixes
      prompt_caching_prefixes:
        enable: true
        min_frequency: 0.1
      bottleneck_analysis:
        # Can also be simple_stack
        enable_nested_stack: true
      concurrency_spike_analysis:
        enable: true
        spike_threshold: 7

  evaluators:
    rag_accuracy:
      _type: ragas
      metric: AnswerAccuracy
      llm_name: nim_rag_eval_llm
    rag_groundedness:
      _type: ragas
      metric: ResponseGroundedness
      llm_name: nim_rag_eval_llm
    rag_relevance:
      _type: ragas
      metric: ContextRelevance
      llm_name: nim_rag_eval_llm
    trajectory_accuracy:
      _type: trajectory
      llm_name: nim_trajectory_eval_llm
